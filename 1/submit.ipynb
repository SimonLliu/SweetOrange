{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"=====================================================================================================================\n",
    "1 读取数据\n",
    "\"\"\"\n",
    "path = \"E:/data2/\"\n",
    "test_transaction = pd.read_csv(path + \"test_transaction_V1.csv\")\n",
    "tag=pd.read_csv(path + \"tag_train_new.csv\")\n",
    "test_operation = pd.read_csv(path + \"test_operation_V1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'=====================================================================================================================\\n3 保存特征\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"=====================================================================================================================\n",
    "2 数据处理\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"【transaction数据】\"\"\"\n",
    "test_transaction_UID = test_transaction.UID\n",
    "## 删去test_transaction 的[\"UID\"]\n",
    "test_transaction.drop([\"UID\"], axis=1, inplace=True)\n",
    "x_test_transaction = test_transaction.values\n",
    "\n",
    "\"\"\"【operation数据】\"\"\"\n",
    "test_operation_UID = test_operation.UID\n",
    "## 删去test_operation 的[\"UID\"]\n",
    "test_operation.drop([\"UID\"], axis=1, inplace=True)\n",
    "x_test_operation = test_operation.values\n",
    "\n",
    "\"\"\"=====================================================================================================================\n",
    "3 保存特征\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'【评估】'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"=====================================================================================================================\n",
    "2 模型预测\n",
    "\"\"\"\n",
    "model_path=\"E:/data2/model/\"\n",
    "clf1=joblib.load(model_path + \"transaction_lr_30.m\")\n",
    "clf2=joblib.load(model_path + \"operation_lr_30.m\")\n",
    "\"\"\"【分类预测】\"\"\"\n",
    "y_test_transaction = clf1.predict(x_test_transaction)\n",
    "y_test_operation = clf2.predict(x_test_operation)\n",
    "\"\"\"【概率预测】\"\"\"\n",
    "y_test_transaction_proba = clf1.predict_proba(x_test_transaction)\n",
    "y_test_operation_proba = clf2.predict_proba(x_test_operation)\n",
    "\n",
    "\"\"\"=====================================================================================================================\n",
    "3 概率文件处理\n",
    "\"\"\"\n",
    "\"\"\"【格式转化】\"\"\"\n",
    "y_test_transaction_proba = DataFrame(y_test_transaction_proba)\n",
    "\n",
    "y_test_operation_proba = DataFrame(y_test_operation_proba)\n",
    "\n",
    "test_transaction_UID = DataFrame(test_transaction_UID)\n",
    "\n",
    "test_operation_UID = DataFrame(test_operation_UID)\n",
    "\n",
    "\"\"\"【概率拼接】\"\"\"\n",
    "y_test_proba = pd.concat(objs=[y_test_transaction_proba, y_test_operation_proba], axis=0, sort=True)\n",
    "\n",
    "\"\"\"【UID拼接】\"\"\"\n",
    "test_UID = pd.concat(objs=[test_transaction_UID, test_operation_UID], axis=0, sort=True)\n",
    "\n",
    "\"\"\"【添加UID】\"\"\"\n",
    "y_test_proba.insert(0, \"UID\", test_UID)\n",
    "\n",
    "\"\"\"【删去第1列】\"\"\"\n",
    "\n",
    "y_test_proba.drop(y_test_proba.columns[1], axis=1, inplace=True)\n",
    "\n",
    "\"\"\"【重命名】\"\"\"\n",
    "\n",
    "y_test_proba.rename(columns={1: \"Tag\"}, inplace=True)\n",
    "\n",
    "\"\"\"【分组并求均值】\"\"\"\n",
    "means = y_test_proba.groupby('UID').mean()['Tag']\n",
    "means2 = DataFrame(means.values)\n",
    "\n",
    "\"\"\"【评估】\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"【保存文件】\"\"\"\n",
    "means=DataFrame(means)\n",
    "means.reset_index(inplace=True)\n",
    "result=means.loc[:,['UID','Tag']]\n",
    "path2=\"E:/data2/result/\"\n",
    "result.to_csv(path2 + 'result_lr_30.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"【在训练集上评估分数】\"\"\"\n",
    "\"\"\"=====================================================================================================================\n",
    "1 读取数据\n",
    "\"\"\"\n",
    "train_transaction = pd.read_csv(path + \"train_transaction_V1.csv\")\n",
    "train_operation = pd.read_csv(path + \"train_operation_V1.csv\")\n",
    "\"\"\"=====================================================================================================================\n",
    "2 数据处理\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"【transaction数据】\"\"\"\n",
    "y_train_transaction = train_transaction.Tag\n",
    "train_transaction_UID=train_transaction.UID\n",
    "\n",
    "## 删去train_transaction 的[\"UID\",\"Tag\"]\n",
    "\n",
    "train_transaction.drop([\"UID\", \"Tag\"], axis=1, inplace=True)\n",
    "x_train_transaction = train_transaction.values\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"【operation数据】\"\"\"\n",
    "y_train_operation = train_operation.Tag\n",
    "train_operation_UID=train_operation.UID\n",
    "## 删去train_operation 的[\"UID\",\"Tag\"]\n",
    "train_operation.drop([\"UID\", \"Tag\"], axis=1, inplace=True)\n",
    "x_train_operation = train_operation.values\n",
    "\n",
    "\n",
    "y_train_transaction_proba = clf1.predict_proba(x_train_transaction)\n",
    "y_train_operation_proba = clf2.predict_proba(x_train_operation)\n",
    "\n",
    "\"\"\"=====================================================================================================================\n",
    "3 概率文件处理\n",
    "\"\"\"\n",
    "\"\"\"【格式转化】\"\"\"\n",
    "y_train_transaction_proba = DataFrame(y_train_transaction_proba)\n",
    "\n",
    "y_train_operation_proba = DataFrame(y_train_operation_proba)\n",
    "\n",
    "train_transaction_UID = DataFrame(train_transaction_UID)\n",
    "\n",
    "train_operation_UID = DataFrame(train_operation_UID)\n",
    "\n",
    "\"\"\"【概率拼接】\"\"\"\n",
    "y_train_proba = pd.concat(objs=[y_train_transaction_proba, y_train_operation_proba], axis=0, sort=True)\n",
    "\n",
    "\"\"\"【UID拼接】\"\"\"\n",
    "train_UID = pd.concat(objs=[train_transaction_UID, train_operation_UID], axis=0, sort=True)\n",
    "\n",
    "\"\"\"【添加UID】\"\"\"\n",
    "y_train_proba.insert(0, \"UID\", train_UID)\n",
    "\n",
    "\"\"\"【删去第1列】\"\"\"\n",
    "\n",
    "y_train_proba.drop(y_train_proba.columns[1], axis=1, inplace=True)\n",
    "\n",
    "\"\"\"【重命名】\"\"\"\n",
    "\n",
    "y_train_proba.rename(columns={1: \"Tag\"}, inplace=True)\n",
    "\n",
    "\"\"\"【分组并求均值】\"\"\"\n",
    "train_means = y_train_proba.groupby('UID').mean()['Tag']\n",
    "train_means = DataFrame(train_means.values)\n",
    "d = pd.DataFrame()\n",
    "d['y'] = tag['Tag']\n",
    "d['prob'] = train_means[0]\n",
    "d = d.sort_values(['prob'], ascending=[0])\n",
    "y = d.y\n",
    "PosAll = y.value_counts()[1]\n",
    "NegAll = y.value_counts()[0]\n",
    "pCumsum = d['y'].cumsum()\n",
    "nCumsum = np.arange(len(y)) - pCumsum + 1\n",
    "pCumsumPer = pCumsum / PosAll\n",
    "nCumsumPer = nCumsum / NegAll\n",
    "TR1 = pCumsumPer[abs(nCumsumPer - 0.001).idxmin()]\n",
    "TR2 = pCumsumPer[abs(nCumsumPer - 0.005).idxmin()]\n",
    "TR3 = pCumsumPer[abs(nCumsumPer - 0.01).idxmin()]\n",
    "a=0.4 * TR1 + 0.3 * TR2 + 0.3 * TR3\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
